{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oskar Lundqvist; osauli-0@student.ltu.se\n",
    "\n",
    "Filip Renberg; filren-0@student.ltu.se\n",
    "\n",
    "We are gonna do a simple lab where we train a model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna use the mnist dataset of digits imported from keras like we did in lab 1 and lab 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "input_shape = (28,28,1)\n",
    "num_classes = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape:  (60000, 28, 28, 1)\n",
      "60000 number of training samples\n",
      "10000 number of testing samples\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "#normalize input values from RGB to Greyscale [0,1]\n",
    "train_data = train_data.astype(\"float32\")/255\n",
    "test_data = test_data.astype(\"float32\")/255\n",
    "#Make sure images have the correct shape(28,28,1)\n",
    "train_data = np.expand_dims(train_data, -1)\n",
    "test_data = np.expand_dims(test_data, -1)\n",
    "\n",
    "#converts class vectors to binary class matrices\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "print(\"training shape: \", train_data.shape)\n",
    "print(train_data.shape[0], \"number of training samples\")\n",
    "print(test_data.shape[0], \"number of testing samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our multi-layer neural network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 13, 13, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 11, 11, 64)        18496     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34826 (136.04 KB)\n",
      "Trainable params: 34826 (136.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=input_shape), #input layer\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=[2,2]),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=[2,2]),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5), #prevents overfitting\n",
    "    layers.Dense(num_classes, activation=\"softmax\") #output layer\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n):\n",
    "    # n = the number of conv2d layers\n",
    "    hidden_layers = []\n",
    "\n",
    "    hidden_layers.append(keras.Input(shape=input_shape)) # input layer\n",
    "    \n",
    "    nr_filter = 32\n",
    "\n",
    "    for i in range(n):\n",
    "        hidden_layers.append(layers.Conv2D(nr_filter, kernel_size=(3, 3), activation=\"relu\"))\n",
    "        hidden_layers.append(layers.MaxPooling2D(pool_size=[2,2]))\n",
    "\n",
    "        nr_filter*=2\n",
    "\n",
    "    hidden_layers.append(layers.Flatten())\n",
    "    hidden_layers.append(layers.Dropout(0.5)) #prevents overfitting\n",
    "    hidden_layers.append(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    model = keras.Sequential(hidden_layers)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are training the model. We can use several different loss functions here, for this project we will use \"categorical_crossentropy\", \"sparse_categorical_crossentropy\" and \"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "size_batch = 128\n",
    "\n",
    "def model_training(pick):\n",
    "    match pick:\n",
    "        case 1:\n",
    "            #categorical loss\n",
    "            model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "            model.fit(train_data, train_labels, batch_size=size_batch, epochs=n_epochs, validation_split=0.1)\n",
    "        case 2:\n",
    "            #sparse categorical loss\n",
    "            model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "            model.fit(train_data, train_labels, batch_size=size_batch, epochs=n_epochs, validation_split=0.1)\n",
    "        case 3:\n",
    "            #binary loss\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "            model.fit(train_data, train_labels, batch_size=size_batch, epochs=n_epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(3)\n",
    "train = model_training(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add evaluation for the trained model with regards to loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.988183319568634\n",
      "loss:  0.009083248674869537\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "score = model.evaluate(train_data, train_labels, verbose=0)\n",
    "print(\"accuracy: \", score[1])\n",
    "print(\"loss: \", score[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
