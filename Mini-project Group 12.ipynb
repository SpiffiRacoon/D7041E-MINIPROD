{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oskar Lundqvist; osauli-0@student.ltu.se\n",
    "\n",
    "Filip Renberg; filren-0@student.ltu.se\n",
    "\n",
    "We are gonna do a simple lab where we train a model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna use the mnist dataset of digits imported from keras like we did in lab 1 and lab 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\oskar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow() # Remove non-important tensorflow warnings\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "input_shape = (28,28,1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape:  (60000, 28, 28, 1)\n",
      "60000 number of training samples\n",
      "10000 number of testing samples\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "#normalize input values from RGB to Greyscale [0,1]\n",
    "train_data = train_data.astype(\"float32\")/255\n",
    "test_data = test_data.astype(\"float32\")/255\n",
    "#Make sure images have the correct shape(28,28,1)\n",
    "train_data = np.expand_dims(train_data, -1)\n",
    "test_data = np.expand_dims(test_data, -1)\n",
    "\n",
    "#converts class vectors to binary class matrices\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "print(\"training shape: \", train_data.shape)\n",
    "print(train_data.shape[0], \"number of training samples\")\n",
    "print(test_data.shape[0], \"number of testing samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our multi-layer neural network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nr_conv2d = 1, nr_filter = 32, kernel_size = (3, 3), model_summary = False):\n",
    "    # Name the model based on the input values, \n",
    "    # model_nr_conv2d-nr_filter-kernel_size\n",
    "    model_name=f\"sequential_{nr_conv2d}-{nr_filter}-{kernel_size[0]}\"\n",
    "    \n",
    "    hidden_layers = []\n",
    "\n",
    "    hidden_layers.append(keras.Input(shape=input_shape)) # input layer\n",
    "\n",
    "    for i in range(nr_conv2d):\n",
    "        hidden_layers.append(layers.Conv2D(nr_filter, kernel_size=kernel_size, activation=\"relu\"))\n",
    "        hidden_layers.append(layers.MaxPooling2D(pool_size=[2,2]))\n",
    "\n",
    "        nr_filter*=2\n",
    "\n",
    "    hidden_layers.append(layers.Flatten())\n",
    "    hidden_layers.append(layers.Dropout(0.5)) #prevents overfitting\n",
    "    hidden_layers.append(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    model = keras.Sequential(hidden_layers, name=model_name)\n",
    "\n",
    "    if model_summary == True:\n",
    "        model.summary()\n",
    "    else:\n",
    "        print(f'Model: {model_name}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are training the model. We can use several different loss functions here, for this project we will use \"categorical_crossentropy\", \"poisson\" and \"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "size_batch = 128\n",
    "\n",
    "def model_training(pick, model):\n",
    "    match pick:\n",
    "        case 1:\n",
    "            #categorical loss function\n",
    "            model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "            print(\"Loss Function: categorical_crossentropy\")\n",
    "            model.fit(train_data, train_labels, batch_size=size_batch, epochs=n_epochs, validation_split=0.1, verbose=0)\n",
    "        case 2:\n",
    "            #poisson loss function\n",
    "            model.compile(loss=\"poisson\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "            print(\"Loss Function: poisson\")\n",
    "            model.fit(train_data, train_labels, batch_size=size_batch, epochs=n_epochs, validation_split=0.1, verbose=0)\n",
    "        case 3:\n",
    "            #binary loss function\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "            print(\"Loss Function: binary_crossentropy\")\n",
    "            model.fit(train_data, train_labels, batch_size=size_batch, epochs=n_epochs, validation_split=0.1, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define different values that we want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_conv2d_list = [1, 2, 3]\n",
    "nr_filter_list = [16, 32, 64]\n",
    "\n",
    "# We use this list to save the values for the best model\n",
    "best_model = [[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_performance(best_model):\n",
    "    # Resulting best model:\n",
    "    create_model(nr_conv2d=best_model[0][2], nr_filter=best_model[0][3], model_summary=True)\n",
    "    match best_model[0][4]:\n",
    "        case 1:\n",
    "            print(\"Using Categorical crossentropy loss function resulted in the \\nfollowing accuracy and loss:\")\n",
    "        case 2:\n",
    "            print(\"Using Poisson loss function resulted in the \\nfollowing accuracy and loss:\")\n",
    "        case 3:\n",
    "            print(\"Using binary crossentropy loss function resulted in the \\nfollowing accuracy and loss\")\n",
    "    print(\"|\\taccuracy: \\t\", best_model[0][0], \"\\t|\")\n",
    "    print(\"|\\tloss: \\t\\t\", best_model[0][1], \"\\t|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We mute model summary for the test prints but you can still see the model name:\n",
      "first value is the nr of conv2d layers, second value is the starting filter size.\n",
      "The third value is the kernel size but we don't change it in our current tests.\n",
      "\n",
      "Model: sequential_1-16-3\n",
      "Loss Function: categorical_crossentropy\n",
      "|\taccuracy: \t 0.9810500144958496 \t|\n",
      "|\tloss: \t\t 0.06741638481616974 \t|\n",
      "\n",
      "\n",
      "Model: sequential_1-16-3\n",
      "Loss Function: poisson\n",
      "|\taccuracy: \t 0.9834666848182678 \t|\n",
      "|\tloss: \t\t 0.10602253675460815 \t|\n",
      "\n",
      "\n",
      "Model: sequential_1-16-3\n",
      "Loss Function: binary_crossentropy\n",
      "|\taccuracy: \t 0.977566659450531 \t|\n",
      "|\tloss: \t\t 0.021184196695685387 \t|\n",
      "\n",
      "\n",
      "Model: sequential_1-32-3\n",
      "Loss Function: categorical_crossentropy\n",
      "|\taccuracy: \t 0.986299991607666 \t|\n",
      "|\tloss: \t\t 0.04987272620201111 \t|\n",
      "\n",
      "\n",
      "Model: sequential_1-32-3\n",
      "Loss Function: poisson\n",
      "|\taccuracy: \t 0.9868333339691162 \t|\n",
      "|\tloss: \t\t 0.1046019122004509 \t|\n",
      "\n",
      "\n",
      "Model: sequential_1-32-3\n",
      "Loss Function: binary_crossentropy\n",
      "|\taccuracy: \t 0.982699990272522 \t|\n",
      "|\tloss: \t\t 0.01656181365251541 \t|\n",
      "\n",
      "\n",
      "Model: sequential_1-64-3\n",
      "Loss Function: categorical_crossentropy\n",
      "|\taccuracy: \t 0.9902999997138977 \t|\n",
      "|\tloss: \t\t 0.03437341749668121 \t|\n",
      "\n",
      "\n",
      "Model: sequential_1-64-3\n",
      "Loss Function: poisson\n",
      "|\taccuracy: \t 0.9906166791915894 \t|\n",
      "|\tloss: \t\t 0.10332940518856049 \t|\n",
      "\n",
      "\n",
      "Model: sequential_1-64-3\n",
      "Loss Function: binary_crossentropy\n",
      "|\taccuracy: \t 0.9864833354949951 \t|\n",
      "|\tloss: \t\t 0.012599710375070572 \t|\n",
      "\n",
      "\n",
      "Model: sequential_2-16-3\n",
      "Loss Function: categorical_crossentropy\n",
      "|\taccuracy: \t 0.9890499711036682 \t|\n",
      "|\tloss: \t\t 0.03729741647839546 \t|\n",
      "\n",
      "\n",
      "Model: sequential_2-16-3\n",
      "Loss Function: poisson\n",
      "|\taccuracy: \t 0.9898666739463806 \t|\n",
      "|\tloss: \t\t 0.10336437076330185 \t|\n",
      "\n",
      "\n",
      "Model: sequential_2-16-3\n",
      "Loss Function: binary_crossentropy\n",
      "|\taccuracy: \t 0.988099992275238 \t|\n",
      "|\tloss: \t\t 0.011289353482425213 \t|\n",
      "\n",
      "\n",
      "Model: sequential_2-32-3\n",
      "Loss Function: categorical_crossentropy\n",
      "|\taccuracy: \t 0.9933333396911621 \t|\n",
      "|\tloss: \t\t 0.022551603615283966 \t|\n",
      "\n",
      "\n",
      "Model: sequential_2-32-3\n",
      "Loss Function: poisson\n",
      "|\taccuracy: \t 0.992983341217041 \t|\n",
      "|\tloss: \t\t 0.10229971259832382 \t|\n",
      "\n",
      "\n",
      "Model: sequential_2-32-3\n",
      "Loss Function: binary_crossentropy\n",
      "|\taccuracy: \t 0.9915333390235901 \t|\n",
      "|\tloss: \t\t 0.007597241085022688 \t|\n",
      "\n",
      "\n",
      "Model: sequential_2-64-3\n",
      "Loss Function: categorical_crossentropy\n",
      "|\taccuracy: \t 0.9961333274841309 \t|\n",
      "|\tloss: \t\t 0.014612764120101929 \t|\n",
      "\n",
      "\n",
      "Model: sequential_2-64-3\n",
      "Loss Function: poisson\n",
      "|\taccuracy: \t 0.995283305644989 \t|\n",
      "|\tloss: \t\t 0.10155846178531647 \t|\n",
      "\n",
      "\n",
      "Model: sequential_2-64-3\n",
      "Loss Function: binary_crossentropy\n",
      "|\taccuracy: \t 0.9946833252906799 \t|\n",
      "|\tloss: \t\t 0.005057575646787882 \t|\n",
      "\n",
      "\n",
      "Model: sequential_3-16-3\n",
      "Loss Function: categorical_crossentropy\n",
      "|\taccuracy: \t 0.9832000136375427 \t|\n",
      "|\tloss: \t\t 0.05431145429611206 \t|\n",
      "\n",
      "\n",
      "Model: sequential_3-16-3\n",
      "Loss Function: poisson\n",
      "|\taccuracy: \t 0.9850000143051147 \t|\n",
      "|\tloss: \t\t 0.10512107610702515 \t|\n",
      "\n",
      "\n",
      "Model: sequential_3-16-3\n",
      "Loss Function: binary_crossentropy\n",
      "|\taccuracy: \t 0.9785333275794983 \t|\n",
      "|\tloss: \t\t 0.018040847033262253 \t|\n",
      "\n",
      "\n",
      "Model: sequential_3-32-3\n",
      "Loss Function: categorical_crossentropy\n",
      "|\taccuracy: \t 0.9916499853134155 \t|\n",
      "|\tloss: \t\t 0.027656598016619682 \t|\n",
      "\n",
      "\n",
      "Model: sequential_3-32-3\n",
      "Loss Function: poisson\n",
      "|\taccuracy: \t 0.9929500222206116 \t|\n",
      "|\tloss: \t\t 0.10251885652542114 \t|\n",
      "\n",
      "\n",
      "Model: sequential_3-32-3\n",
      "Loss Function: binary_crossentropy\n",
      "|\taccuracy: \t 0.9904000163078308 \t|\n",
      "|\tloss: \t\t 0.007138917688280344 \t|\n",
      "\n",
      "\n",
      "Model: sequential_3-64-3\n",
      "Loss Function: categorical_crossentropy\n",
      "|\taccuracy: \t 0.9962666630744934 \t|\n",
      "|\tloss: \t\t 0.012779220938682556 \t|\n",
      "\n",
      "\n",
      "Model: sequential_3-64-3\n",
      "Loss Function: poisson\n",
      "|\taccuracy: \t 0.9967666864395142 \t|\n",
      "|\tloss: \t\t 0.1012289896607399 \t|\n",
      "\n",
      "\n",
      "Model: sequential_3-64-3\n",
      "Loss Function: binary_crossentropy\n",
      "|\taccuracy: \t 0.9955666661262512 \t|\n",
      "|\tloss: \t\t 0.0035443163942545652 \t|\n",
      "\n",
      "\n",
      "Finally done :)\n"
     ]
    }
   ],
   "source": [
    "print(\"We mute model summary for the test prints but you can still see the model name:\")\n",
    "print(\"first value is the nr of conv2d layers, second value is the starting filter size.\")\n",
    "print(\"The third value is the kernel size but we don't change it in our current tests.\\n\")\n",
    "\n",
    "for i in nr_conv2d_list: # The nr conv2d layers\n",
    "    for j in nr_filter_list: # The starting size of the conv2d filters\n",
    "        for n in range(3):\n",
    "\n",
    "            model = create_model(nr_conv2d=i, nr_filter=j, kernel_size=(3, 3)) # You can also change the kernel size\n",
    "            train = model_training(n+1, model)\n",
    "\n",
    "            #evaluate\n",
    "            score = model.evaluate(train_data, train_labels, verbose=0)\n",
    "            print(\"|\\taccuracy: \\t\", score[1], \"\\t|\")\n",
    "            print(\"|\\tloss: \\t\\t\", score[0], \"\\t|\")\n",
    "\n",
    "            if (score[1] > best_model[0][0]) & (score[0] < best_model[0][1]):\n",
    "                best_model.pop()\n",
    "                best_model.append((score[1], score[0], i, j, n+1))\n",
    "\n",
    "            print(\"\\n\")\n",
    "\n",
    "print(\"Finally done :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the best performing model from our tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3-64-3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPooli  (None, 13, 13, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 11, 11, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPooli  (None, 5, 5, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 3, 3, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_62 (MaxPooli  (None, 1, 1, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 372234 (1.42 MB)\n",
      "Trainable params: 372234 (1.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Using Categorical crossentropy loss function resulted in the \n",
      "following accuracy and loss:\n",
      "|\taccuracy: \t 0.9962666630744934 \t|\n",
      "|\tloss: \t\t 0.012779220938682556 \t|\n"
     ]
    }
   ],
   "source": [
    "best_performance(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
