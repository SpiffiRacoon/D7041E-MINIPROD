{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oskar Lundqvist; osauli-0@student.ltu.se\n",
    "\n",
    "Filip Renberg; filren-0@student.ltu.se\n",
    "\n",
    "We are gonna do a simple lab where we train a model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna use the mnist dataset of digits imported from keras like we did in lab 1 and lab 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow() # Remove non-important tensorflow warnings\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "input_shape = (28,28,1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "#normalize input values from RGB to Greyscale [0,1]\n",
    "train_data = train_data.astype(\"float32\")/255\n",
    "test_data = test_data.astype(\"float32\")/255\n",
    "#Make sure images have the correct shape(28,28,1)\n",
    "train_data = np.expand_dims(train_data, -1)\n",
    "test_data = np.expand_dims(test_data, -1)\n",
    "\n",
    "#converts class vectors to binary class matrices\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "print(\"training shape: \", train_data.shape)\n",
    "print(train_data.shape[0], \"number of training samples\")\n",
    "print(test_data.shape[0], \"number of testing samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our multi-layer neural network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nr_conv2d = 1, nr_filter = 32, kernel_size = (3, 3), model_summary = False):\n",
    "    # Name the model based on the input values, \n",
    "    # model_nr_conv2d-nr_filter-kernel_size\n",
    "    model_name=f\"sequential_{nr_conv2d}-{nr_filter}-{kernel_size[0]}\"\n",
    "    \n",
    "    hidden_layers = []\n",
    "\n",
    "    hidden_layers.append(keras.Input(shape=input_shape)) # input layer\n",
    "\n",
    "    for i in range(nr_conv2d):\n",
    "        hidden_layers.append(layers.Conv2D(nr_filter, kernel_size=kernel_size, activation=\"relu\"))\n",
    "        hidden_layers.append(layers.MaxPooling2D(pool_size=[2,2]))\n",
    "\n",
    "        nr_filter*=2\n",
    "\n",
    "    hidden_layers.append(layers.Flatten())\n",
    "    hidden_layers.append(layers.Dropout(0.5)) #prevents overfitting\n",
    "    hidden_layers.append(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    model = keras.Sequential(hidden_layers, name=model_name)\n",
    "\n",
    "    if model_summary == True:\n",
    "        model.summary()\n",
    "    else:\n",
    "        print(f'Model: {model_name}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are training the model. We can use several different loss functions here, for this project we will use \"categorical_crossentropy\", \"sparse_categorical_crossentropy\" and \"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "size_batch = 128\n",
    "\n",
    "def model_training(pick, model):\n",
    "    match pick:\n",
    "        case 1:\n",
    "            #categorical loss function\n",
    "            model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "            print(\"Loss Function: categorical_crossentropy\")\n",
    "            model.fit(train_data, train_labels, batch_size=size_batch, epochs=n_epochs, validation_split=0.1, verbose=0)\n",
    "        case 2:\n",
    "            #poisson loss function\n",
    "            model.compile(loss=\"poisson\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "            print(\"Loss Function: poisson\")\n",
    "            model.fit(train_data, train_labels, batch_size=size_batch, epochs=n_epochs, validation_split=0.1, verbose=0)\n",
    "        case 3:\n",
    "            #binary loss function\n",
    "            model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "            print(\"Loss Function: binary_crossentropy\")\n",
    "            model.fit(train_data, train_labels, batch_size=size_batch, epochs=n_epochs, validation_split=0.1, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define for the test diffrent values we want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_conv2d_list = [1, 2, 3]\n",
    "nr_filter_list = [16, 32, 64]\n",
    "\n",
    "# We use this list to save the values for the best model\n",
    "best_model = [[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_performance(best_model):\n",
    "    # Resulting best model:\n",
    "    create_model(nr_conv2d=best_model[0][2], nr_filter=best_model[0][3])\n",
    "    match best_model[0][4]:\n",
    "        case 1:\n",
    "            print(\"Using Categorical crossentropy loss function it gave us the \\nfollowing accuracy and loss:\")\n",
    "        case 2:\n",
    "            print(\"Using Poisson loss function it gave us the \\nfollowing accuracy and loss:\")\n",
    "        case 3:\n",
    "            print(\"Using binary crossentropy loss function it gave us the \\nfollowing accuracy and loss\")\n",
    "    print(\"|\\taccuracy: \\t\", best_model[0][0], \"\\t|\")\n",
    "    print(\"|\\tloss: \\t\\t\", best_model[0][1], \"\\t|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We mute model summary for the test prints but you can still see the model name:\")\n",
    "print(\"first value is the nr of conv2d layers, second value is the starting filter size.\")\n",
    "print(\"The fird value is the kernel size but we don't change it in our tests.\\n\")\n",
    "\n",
    "for i in nr_conv2d_list: # The nr conv2d layers\n",
    "    for j in nr_filter_list: # The starting size of the conv2d filters\n",
    "        for n in range(3):\n",
    "\n",
    "            model = create_model(nr_conv2d=i, nr_filter=j, kernel_size=(3, 3)) # You can also change kernel size\n",
    "            train = model_training(n+1, model)\n",
    "\n",
    "            #evaluate\n",
    "            score = model.evaluate(train_data, train_labels, verbose=0)\n",
    "            print(\"|\\taccuracy: \\t\", score[1], \"\\t|\")\n",
    "            print(\"|\\tloss: \\t\\t\", score[0], \"\\t|\")\n",
    "\n",
    "            if (score[1] > best_model[0][0]) & (score[0] < best_model[0][1]):\n",
    "                best_model.pop()\n",
    "                best_model.append((score[1], score[0], i, j, n+1))\n",
    "\n",
    "            print(\"\\n\")\n",
    "\n",
    "print(\"Finally done :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the best performing model from our tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_performance(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
